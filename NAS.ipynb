{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Error(Exception):\n",
    "    def __init__(self, expr = None, msg = None):\n",
    "        self.expr = expr\n",
    "        self.msg = msg\n",
    "class inputSmallerThanKernel(Error):\n",
    "    def __init__():\n",
    "        super(inputSmallerThanKernel, self).__init__()\n",
    "class nodeDoesNotExist(Error):\n",
    "    def __init__():\n",
    "        super(nodeDoesNotExist, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class node(object):\n",
    "    nodes = []\n",
    "    def __init__(self, input_shape = (0, 0, 0), output_shape = (0, 0, 0)): # c, i1, i2\n",
    "        node.nodes.append(self)\n",
    "        self.no  = len(node.nodes)\n",
    "        self.in_adj = []\n",
    "        self.out_adj = []\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.compatible = True\n",
    "            \n",
    "    def node_alright(self, curr_node):\n",
    "        try:\n",
    "            assert(issubclass(type(curr_node), node))\n",
    "        except:\n",
    "            raise Error('Not a node')\n",
    "# Put this section in graph class\n",
    "#         try:\n",
    "#             assert(curr_node in graph_nodes)\n",
    "#         except:\n",
    "#             raise nodeDoesNotExist\n",
    "    \n",
    "    def determine_compatibility(self):\n",
    "        for curr_node in self.in_adj:\n",
    "            curr = (curr_node.output_shape == self.input_shape)\n",
    "            self.compatible  = self.compatible and curr\n",
    "            \n",
    "        for curr_node in self.out_adj:\n",
    "            curr = (curr_node.input_shape == self.output_shape)\n",
    "            self.compatible = self.compatible and curr\n",
    "\n",
    "    def describe_adj_list(self, in_adj, out_adj):\n",
    "        for curr_node in in_adj + out_adj:\n",
    "            try:\n",
    "                node_alright(curr_node)\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "        self.in_adj = in_adj\n",
    "        self.out_adj = out_adj\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "            \n",
    "    def out_shape(self):\n",
    "        pass\n",
    "    \n",
    "    def remove(self):\n",
    "        ## needed in graph class\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.no) + \" \" + str(type(self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class convolution_block(nn.Module, node):\n",
    "    all_convs = []\n",
    "    \n",
    "    def __init__(self, in_h, in_w, in_channels, out_channels, kernel_size, padding = 0, stride = 1):\n",
    "        try:\n",
    "            assert(min(in_h, in_w) +2*padding > kernel_size)\n",
    "        except:\n",
    "            raise inputSmallerThanKernel\n",
    "        super(convolution_block, self).__init__()\n",
    "        node.__init__(self, (in_channels, in_h, in_w))\n",
    "        convolution_block.all_convs.append(self)\n",
    "        self.in_channels  = in_channels\n",
    "        self.out_channels = out_channels \n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride \n",
    "        self.padding = padding\n",
    "        self.output_shape = self.out_shape()\n",
    "        \n",
    "        # NN Layers\n",
    "        self.conv_layer = nn.Conv2d(self.in_channels, self.out_channels, self.kernel_size, self.stride, self.padding)\n",
    "        self.batch_norm = nn.BatchNorm2d(self.out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "    def out_shape(self):\n",
    "        c, h, w = self.input_shape\n",
    "        C = self.out_channels\n",
    "        H = (h + 2*self.padding - self.kernel_size)/self.stride + 1\n",
    "        W = (w + 2*self.padding - self.kernel_size)/self.stride + 1\n",
    "        return (C, H, W)\n",
    "    \n",
    "#     def determine_compatibility(self):\n",
    "#         super(convolution_block, self).determine_compatibility()\n",
    "#         self.compatible  = self.compatible and (len(self.in_adj) == 1)\n",
    "\n",
    "    def describe_adj_list(self, in_adj, out_adj):\n",
    "        try:\n",
    "            assert(len(in_adj) == 1)\n",
    "        except:\n",
    "            raise Error('A convolution block can have only one in-edge')\n",
    "        super(merge_node, self).describe_adj_list(in_adj, out_adj)\n",
    "\n",
    "    \n",
    "    def remove(self): \n",
    "        ### Remove from all_convs list\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class max_pool_node(nn.Module, node):\n",
    "    all_max_pools = []\n",
    "    \n",
    "    def __init__(self, in_h, in_w, in_channels, kernel_size, padding = 0, stride = 1):\n",
    "        try:\n",
    "            assert(min(in_h, in_w) +2*padding > kernel_size)\n",
    "        except:\n",
    "            raise inputSmallerThanKernel\n",
    "        super(max_pool_node, self).__init__()    \n",
    "        node.__init__(self, (in_channels, in_h, in_w))\n",
    "        max_pool_node.all_max_pools.append(self)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride \n",
    "        self.padding = padding\n",
    "        self.output_shape = self.out_shape()\n",
    "        \n",
    "        ## NN Layer\n",
    "        self.max_pool_layer = nn.MaxPool2d(self.kernel_size, self.stride, self.padding)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.max_pool_layer(x)\n",
    "    \n",
    "    def out_shape(self):\n",
    "        c, h, w = self.input_shape\n",
    "        C = c\n",
    "        H = (h + 2*self.padding - self.kernel_size)/self.stride + 1\n",
    "        W = (w + 2*self.padding - self.kernel_size)/self.stride + 1\n",
    "        return (C, H, W)\n",
    "    \n",
    "#     def determine_compatibility(self):\n",
    "#         super(max_pool_node, self).determine_compatibility()\n",
    "#         self.compatible  = self.compatible and (len(self.in_adj) == 1)\n",
    "\n",
    "    def describe_adj_list(self, in_adj, out_adj):\n",
    "        try:\n",
    "            assert(len(in_adj) == 1)\n",
    "        except:\n",
    "            raise Error('A max-pool block can have only one in-edge')\n",
    "        super(merge_node, self).describe_adj_list(in_adj, out_adj)\n",
    "\n",
    "    \n",
    "    def remove(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Is is it required to be to a derived class of nn.Module ?\n",
    "class merge_node(nn.Module, node):\n",
    "    all_merge_nodes = []\n",
    "    \n",
    "    def __init__(self, parents, child):\n",
    "        super(merge_node, self).__init__()\n",
    "        node.__init__(self)\n",
    "        try:\n",
    "            self.describe_adj_list([parents[0], parents[1]], [child])\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        merge_node.all_merge_nodes.append(self)\n",
    "        \n",
    "    def describe_adj_list(self, in_adj, out_adj):\n",
    "        try:\n",
    "            assert(len(in_adj) == 2)\n",
    "        except:\n",
    "            raise Error('Parents must be exactly two')\n",
    "        super(merge_node, self).describe_adj_list(in_adj, out_adj)\n",
    "        \n",
    "        \n",
    "class add_node(merge_node):\n",
    "    all_add_nodes = []\n",
    "    \n",
    "    def __init__(self, parents, child):\n",
    "        super(add_node, self).__init__(parents, child)\n",
    "        add_node.all_add_nodes.append(self)\n",
    "        self.input_shape = self.in_adj[0].output_shape\n",
    "        self.output_shape = self.out_shape()\n",
    "    \n",
    "    ### Does it allow to input paramteters ?\n",
    "    def forward(self, x, y):\n",
    "        return x+y ### Check if their data strcutre type supports this addition\n",
    "        \n",
    "    def out_shape(self):\n",
    "        return self.input_shape\n",
    "    \n",
    "class concat_node(merge_node):\n",
    "    # Define Later\n",
    "    pass\n",
    "\n",
    "class convex_merge_node(merge_node):\n",
    "    # Define Later\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    def __init__(self):\n",
    "        self.adj_mat = {}\n",
    "        self.adj_list = {}\n",
    "        self.nodes = set()\n",
    "        self.int_to_node = {}\n",
    "        self.conv_blocks = []\n",
    "        self.max_pool_blocks = [] # Change naming conv maybe ?\n",
    "        self.topsort = []\n",
    "        \n",
    "    def __init__(self, adj_list, int_to_node):\n",
    "        try:\n",
    "            assert(type(adj_list) == dict)\n",
    "        except:\n",
    "            raise Error('adj_list should be a dictionary')\n",
    "        for _, li in adj_list.items():\n",
    "            try:\n",
    "                assert(type(li) == list)\n",
    "                assert(len(li) == 2)\n",
    "                assert(li[0] == list and li[1] == list)\n",
    "            except:\n",
    "                raise Error('Each mapping in adj_list should be to a two-dim list')\n",
    "            try:\n",
    "                assert(sorted(adj_list.keys()) == sorted(int_to_node.keys()))\n",
    "            except:\n",
    "                raise Error('Mismatch between nodes in adj_list and int_to_node')\n",
    "        \n",
    "        self.adj_list = adj_list\n",
    "        self.adj_mat = self.get_adj_mat(self.adj_list)\n",
    "        self.nodes = set(int_to_node.keys())\n",
    "        self.int_to_node = int_to_node\n",
    "        self.conv_blocks, self.max_pool_blocks = self.get_conv_and_max_pool_blocks()\n",
    "        self.topsort = self.topsorting()\n",
    "        \n",
    "    def __init__(self, random_init):\n",
    "        if random_init:\n",
    "            # Do random network construction\n",
    "            pass\n",
    "        else:\n",
    "            self.__init__()\n",
    "        \n",
    "    def get_adj_mat(self, adj_list):\n",
    "        adj_mat = {}\n",
    "        nodes = adj_list.keys()\n",
    "        for x in nodes:\n",
    "            adj_mat[x] = {}\n",
    "            for y in nodes:\n",
    "                adj_mat[x][y] = 0\n",
    "        for node, li in adj_list.items():\n",
    "            for child in li:\n",
    "                adj_mat[node][child] = 1\n",
    "        return adj_mat\n",
    "    \n",
    "    def get_conv_and_max_pool_blocks(self):\n",
    "        conv_blocks = []\n",
    "        max_pool_blocks = []\n",
    "        for x in self.nodes:\n",
    "            if isinstance(self.int_to_node[x], convolution_block):\n",
    "                conv_blocks.append(x)\n",
    "            elif isinstance(self.int_to_node[x], max_pool_node):\n",
    "                max_pool_blocks.append(x)\n",
    "        return (conv_blocks, max_pool_blocks)\n",
    "    \n",
    "    def topsorting(self):\n",
    "        # level problem\n",
    "        topsort = []\n",
    "        import Queue\n",
    "        in_deg = {}\n",
    "        q = queue.Queue()\n",
    "        for node in self.nodes:\n",
    "            val = len(self.int_to_node[node].in_adj)\n",
    "            if val == 0:\n",
    "                q.put(node)\n",
    "            in_deg[node] = val\n",
    "            \n",
    "        while not q.empty():\n",
    "            curr_node = q.get()\n",
    "            topsort.append(curr_node)\n",
    "            for child in self.adj_list[curr_node]:\n",
    "                in_deg[child] -= 1\n",
    "                if in_deg[child] == 0:\n",
    "                    q.put(child)\n",
    "        return topsort\n",
    "    \n",
    "    \n",
    "    def morphism(self):\n",
    "        import random\n",
    "        actions = {'deepen': self.deepen_morph, \n",
    "                   'widen': self.widen_morph, \n",
    "                   'skip-connection': self.skip_morph }\n",
    "        choice = random.choice(actions)\n",
    "        actions[choice]()\n",
    "    \n",
    "    def deepen_morph(self):\n",
    "        deepen_conv_block = self.int_to_node[random.choice(self.conv_blocks)]\n",
    "        kernel_size = random.choice([3, 5])\n",
    "        in_channels, in_h, in_w = deepen_conv_block.output_shape\n",
    "        out_channels = in_channels\n",
    "        identity_conv_block = convolution_block(in_h, in_w, in_channels, out_channels, kernel_size, (kernel_size-1)/2)\n",
    "        ## make connections \n",
    "        identity_conv_block.describe_adj_list([deepen_conv_block], deepen_conv_block.out_adj)\n",
    "        deepen_conv_block.describe_adj_list(deepen_conv_block.in_adj, [identity_conv_block])\n",
    "        weights = identity_conv_block.conv_layer.weight.data\n",
    "        for channel in range(out_channels):\n",
    "            for i in range(in_channels):\n",
    "                for j in range(kernel_size):\n",
    "                    for k in range(kernel_size):\n",
    "                        weights[channel][i][j][k] = (channel == i) and (j == k) and j == (kernel_size)/2 \n",
    "                            \n",
    "        ## weights\n",
    "\n",
    "        \n",
    "\n",
    "    def widen_morph(self):\n",
    "        pass\n",
    "    \n",
    "    def skip_morph(self):\n",
    "        pass\n",
    "    \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'set' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-d6a8032a5d5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'deepen'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'widen'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'skip-connection'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/python@2/2.7.15/Frameworks/Python.framework/Versions/2.7/lib/python2.7/random.pyc\u001b[0m in \u001b[0;36mchoice\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;34m\"\"\"Choose a random element from a non-empty sequence.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# raises IndexError if seq is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'set' object does not support indexing"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.choice(['deepen', 'widen', 'skip-connection'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
