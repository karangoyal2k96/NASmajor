{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from graphviz import Digraph\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Error(Exception):\n",
    "    def __init__(self, expr = None, msg = None):\n",
    "        self.expr = expr\n",
    "        self.msg = msg\n",
    "class inputSmallerThanKernel(Error):\n",
    "    def __init__(self):\n",
    "        super(inputSmallerThanKernel, self).__init__()\n",
    "class nodeDoesNotExist(Error):\n",
    "    def __init__(self):\n",
    "        super(nodeDoesNotExist, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class node(object):\n",
    "    nodes = []\n",
    "    def __init__(self, input_shape = (0, 0, 0), output_shape = (0, 0, 0)): # c, i1, i2\n",
    "        node.nodes.append(self)\n",
    "        self.no  = len(node.nodes)\n",
    "        self.in_adj = []\n",
    "        self.out_adj = []\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.compatible = True\n",
    "            \n",
    "    def node_alright(self, curr_node):\n",
    "        try:\n",
    "            assert(issubclass(type(curr_node), node))\n",
    "        except:\n",
    "            raise Error('Not a node' + str(type(curr_node)))\n",
    "# Put this section in graph class\n",
    "#         try:\n",
    "#             assert(curr_node in graph_nodes)\n",
    "#         except:\n",
    "#             raise nodeDoesNotExist\n",
    "    \n",
    "    def determine_compatibility(self):\n",
    "        for curr_node in self.in_adj:\n",
    "            curr = (curr_node.output_shape == self.input_shape)\n",
    "            self.compatible  = self.compatible and curr\n",
    "            \n",
    "        for curr_node in self.out_adj:\n",
    "            curr = (curr_node.input_shape == self.output_shape)\n",
    "            self.compatible = self.compatible and curr\n",
    "\n",
    "    def describe_adj_list(self, in_adj, out_adj):\n",
    "        assert isinstance(in_adj, list), 'in_adj must be a list'\n",
    "        assert isinstance(in_adj, list), 'out_adj must be a list'\n",
    "        for curr_node in in_adj + out_adj:\n",
    "            try:\n",
    "                self.node_alright(curr_node)\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "        self.in_adj = in_adj\n",
    "        self.out_adj = out_adj\n",
    "\n",
    "    def out_shape(self):\n",
    "        pass\n",
    "    \n",
    "    def remove(self):\n",
    "        ## needed in graph class\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(type(self)) + \" \" + str(self.no)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class convolution_block(nn.Module, node):\n",
    "    all_convs = []\n",
    "    \n",
    "    def __init__(self, in_h, in_w, in_channels, out_channels, kernel_size, padding = 0, stride = 1):\n",
    "        try:\n",
    "            assert(min(in_h, in_w) +2*padding >= kernel_size)\n",
    "        except:\n",
    "            raise inputSmallerThanKernel\n",
    "        super(convolution_block, self).__init__()\n",
    "        node.__init__(self, (in_channels, in_h, in_w))\n",
    "        convolution_block.all_convs.append(self)\n",
    "        self.in_channels  = in_channels\n",
    "        self.out_channels = out_channels \n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride \n",
    "        self.padding = padding\n",
    "        self.output_shape = self.out_shape()\n",
    "        \n",
    "        # NN Layers\n",
    "        self.conv_layer = nn.Conv2d(self.in_channels, self.out_channels, self.kernel_size, self.stride, self.padding)\n",
    "        self.batch_norm = nn.BatchNorm2d(self.out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "    def out_shape(self):\n",
    "        c, h, w = self.input_shape\n",
    "        C = self.out_channels\n",
    "        H = (h + 2*self.padding - self.kernel_size)/self.stride + 1\n",
    "        W = (w + 2*self.padding - self.kernel_size)/self.stride + 1\n",
    "        return (C, H, W)\n",
    "    \n",
    "#     def determine_compatibility(self):\n",
    "#         super(convolution_block, self).determine_compatibility()\n",
    "#         self.compatible  = self.compatible and (len(self.in_adj) == 1)\n",
    "\n",
    "    def describe_adj_list(self, in_adj, out_adj):\n",
    "        super(convolution_block, self).describe_adj_list(in_adj, out_adj)\n",
    "        try:\n",
    "            assert(len(in_adj) == 1)\n",
    "        except:\n",
    "            print(in_adj)\n",
    "            raise Error('A convolution block can have only one in-edge')\n",
    "    \n",
    "    def remove(self): \n",
    "        ### Remove from all_convs list\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class max_pool_node(nn.Module, node):\n",
    "    all_max_pools = []\n",
    "    \n",
    "    def __init__(self, in_h, in_w, in_channels, kernel_size, padding = 0, stride = 1):\n",
    "        try:\n",
    "            assert(min(in_h, in_w) +2*padding > kernel_size)\n",
    "        except:\n",
    "            raise inputSmallerThanKernel\n",
    "        super(max_pool_node, self).__init__()    \n",
    "        node.__init__(self, (in_channels, in_h, in_w))\n",
    "        max_pool_node.all_max_pools.append(self)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride \n",
    "        self.padding = padding\n",
    "        self.output_shape = self.out_shape()\n",
    "        \n",
    "        ## NN Layer\n",
    "        self.max_pool_layer = nn.MaxPool2d(self.kernel_size, self.stride, self.padding)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.max_pool_layer(x)\n",
    "    \n",
    "    def out_shape(self):\n",
    "        c, h, w = self.input_shape\n",
    "        C = c\n",
    "        H = (h + 2*self.padding - self.kernel_size)/self.stride + 1\n",
    "        W = (w + 2*self.padding - self.kernel_size)/self.stride + 1\n",
    "        return (C, H, W)\n",
    "    \n",
    "#     def determine_compatibility(self):\n",
    "#         super(max_pool_node, self).determine_compatibility()\n",
    "#         self.compatible  = self.compatible and (len(self.in_adj) == 1)\n",
    "\n",
    "    def describe_adj_list(self, in_adj, out_adj):\n",
    "        super(max_pool_node, self).describe_adj_list(in_adj, out_adj)\n",
    "        try:\n",
    "            assert(len(in_adj) == 1)\n",
    "        except:\n",
    "            raise Error('A max-pool block can have only one in-edge')\n",
    "\n",
    "    def remove(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Is is it required to be to a derived class of nn.Module ?\n",
    "class merge_node(node):\n",
    "    all_merge_nodes = []\n",
    "    \n",
    "    def __init__(self, parents, child):\n",
    "        super(merge_node, self).__init__()\n",
    "#         node.__init__(self)\n",
    "        try:\n",
    "            self.describe_adj_list(parents, child)\n",
    "        except Exception as e:\n",
    "            print e.expr\n",
    "            raise e\n",
    "        merge_node.all_merge_nodes.append(self)\n",
    "        \n",
    "    def describe_adj_list(self, in_adj, out_adj):\n",
    "        super(merge_node, self).describe_adj_list(in_adj, out_adj)\n",
    "        try:\n",
    "            assert(len(in_adj) == 2)\n",
    "        except:\n",
    "            raise Error('Parents must be exactly two')\n",
    "        \n",
    "class add_node(nn.Module, merge_node):\n",
    "    all_add_nodes = []\n",
    "    \n",
    "    def __init__(self, parents, child):\n",
    "        super(add_node, self).__init__()\n",
    "        merge_node.__init__(self, parents, child)\n",
    "        add_node.all_add_nodes.append(self)\n",
    "        self.input_shape = self.in_adj[0].output_shape\n",
    "        self.output_shape = self.out_shape()\n",
    "                \n",
    "    ### Does it allow to input paramteters ?\n",
    "    def forward(self, x, y):\n",
    "        return x+y ### Check if their data strcutre type supports this addition\n",
    "        \n",
    "    def out_shape(self):\n",
    "        return self.input_shape\n",
    "    \n",
    "class concat_node(merge_node):\n",
    "    # Define Later\n",
    "    pass\n",
    "\n",
    "class convex_merge_node(merge_node):\n",
    "    # Define Later\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    def __init__(self):\n",
    "        self.adj_mat = {}\n",
    "        self.adj_list = {}\n",
    "        self.nodes = []\n",
    "        self.int_to_node = {}\n",
    "        self.node_to_int = {}\n",
    "        self.conv_blocks = []\n",
    "        self.max_pool_blocks = [] # Change naming conv maybe ?\n",
    "        self.topsort = []\n",
    "        self.rank_in_topsort = {}\n",
    "        self.max_no = 0\n",
    "        \n",
    "    def __init__(self, adj_list, int_to_node):\n",
    "        assert isinstance(int_to_node, dict), 'int_to_node must be a dictionary'\n",
    "        for _, cnode in int_to_node.items():\n",
    "            assert isinstance(cnode, node), 'mapping in int_to_node should be to a node'\n",
    "        \n",
    "        assert isinstance(adj_list, dict), 'adj_list should be a dictionary'\n",
    "        assert(len(int_to_node) == len(adj_list))\n",
    "        for cnode, li in adj_list.items():\n",
    "            assert cnode in int_to_node, 'mismatch between int_to_node and adj_list'\n",
    "            try:\n",
    "                assert(isinstance(li, list))\n",
    "                assert(len(li) == 2)\n",
    "                assert(isinstance(li[0], list) and isinstance(li[1], list))\n",
    "            except:\n",
    "                raise Error('Each mapping in adj_list should be to a two-dim list')\n",
    "            for child_node in li[0]:\n",
    "                assert child_node in int_to_node, 'mismatch between int_to_node and adj_list'\n",
    "            for child_node in li[1]:\n",
    "                assert child_node in int_to_node, 'mismatch between int_to_node and adj_list'\n",
    "\n",
    "        self.adj_list = adj_list\n",
    "        self.adj_mat = self.get_adj_mat(self.adj_list)\n",
    "        self.nodes = int_to_node.keys()\n",
    "        self.int_to_node = int_to_node\n",
    "        self.node_to_int = self.get_node_to_int(self.int_to_node)\n",
    "        self.max_no = max(self.int_to_node)\n",
    "        self.conv_blocks, self.max_pool_blocks = self.get_conv_and_max_pool_blocks()\n",
    "        self.topsort = []\n",
    "        self.rank_in_topsort = {}\n",
    "        self.topsort\n",
    "        self.topsorting()\n",
    "        \n",
    "#     def __init__(self, random_init):\n",
    "#         if random_init:\n",
    "#             # Do random network construction\n",
    "#             pass\n",
    "#         else:\n",
    "#             self.__init__()\n",
    "    \n",
    "    def get_node_to_int(self, int_to_node):\n",
    "        node_to_int = {}\n",
    "        for no, cnode in int_to_node.items():\n",
    "            node_to_int[cnode] = no\n",
    "        return node_to_int\n",
    "\n",
    "        \n",
    "    def get_adj_mat(self, adj_list):\n",
    "        adj_mat = {}\n",
    "        nodes = adj_list.keys()\n",
    "        for x in nodes:\n",
    "            adj_mat[x] = {}\n",
    "            for y in nodes:\n",
    "                adj_mat[x][y] = 0\n",
    "        for cnode, li in adj_list.items():\n",
    "            for par in li[0]:\n",
    "                adj_mat[par][cnode] = 1\n",
    "            for child in li[1]:\n",
    "                adj_mat[cnode][child] = 1\n",
    "        return adj_mat\n",
    "    \n",
    "    def get_conv_and_max_pool_blocks(self):\n",
    "        conv_blocks = []\n",
    "        max_pool_blocks = []\n",
    "        for x in self.nodes:\n",
    "            if isinstance(self.int_to_node[x], convolution_block):\n",
    "                conv_blocks.append(x)\n",
    "            elif isinstance(self.int_to_node[x], max_pool_node):\n",
    "                max_pool_blocks.append(x)\n",
    "        return (conv_blocks, max_pool_blocks)\n",
    "    \n",
    "    def topsorting(self):\n",
    "        # level problem\n",
    "        topsort = []\n",
    "        import Queue\n",
    "        in_deg = {}\n",
    "        q = Queue.Queue()\n",
    "        for node in self.nodes:\n",
    "            val  = len(self.adj_list[node][0])\n",
    "#             val = len(self.int_to_node[node].in_adj)\n",
    "            if val == 0:\n",
    "                q.put(node)\n",
    "            in_deg[node] = val\n",
    "            \n",
    "        while not q.empty():\n",
    "            curr_node = q.get()\n",
    "            topsort.append(curr_node)\n",
    "            for child in self.adj_list[curr_node][1]:\n",
    "                in_deg[child] -= 1\n",
    "                if in_deg[child] == 0:\n",
    "                    q.put(child)\n",
    "        self.topsort = topsort\n",
    "        self.set_rank_in_topsort()\n",
    "    \n",
    "    def set_rank_in_topsort(self):\n",
    "        for ind, node_no in enumerate(self.topsort):\n",
    "            self.rank_in_topsort[node_no]  = ind\n",
    "    \n",
    "    def add_nodes_to_network(self, nodes):\n",
    "        ### loophole here, assumption is that all changed nodes are being provided to the function\n",
    "        ### for now, lets go on with it, but its an issue\n",
    "        for curr_node in nodes:\n",
    "            curr_node.determine_compatibility()\n",
    "            if not curr_node.compatible:\n",
    "                raise Error('Node is not compatible with the graph') \n",
    "        for curr_node in nodes:\n",
    "            if curr_node not in self.node_to_int:\n",
    "                self.max_no += 1\n",
    "                self.adj_mat[self.max_no] = {}\n",
    "                self.adj_list[self.max_no] = []\n",
    "                self.node_to_int[curr_node] = self.max_no\n",
    "                self.int_to_node[self.max_no] = curr_node\n",
    "                self.nodes.append(self.max_no)\n",
    "                if isinstance(curr_node, convolution_block):\n",
    "                    self.conv_blocks.append(self.max_no)\n",
    "                elif isinstance(curr_node, max_pool_node):\n",
    "                    self.max_pool_blocks.append(self.max_no)\n",
    "        for curr_node in nodes:\n",
    "            no = self.node_to_int[curr_node]\n",
    "            self.adj_list[no] = [map(lambda x: self.node_to_int[x], curr_node.in_adj), map(lambda x: self.node_to_int[x], curr_node.out_adj)]\n",
    "            for par in self.adj_list[no][0]:\n",
    "                self.adj_mat[par][no] = 1\n",
    "            for child in self.adj_list[no][0]:\n",
    "                self.adj_mat[no][child] = 1\n",
    "        self.topsorting()\n",
    "        \n",
    "    def morphism(self):\n",
    "        import random\n",
    "        actions = {'deepen': self.deepen_morph, \n",
    "                   'widen': self.widen_morph, \n",
    "                   'skip-connection': self.skip_morph }\n",
    "        choice = random.choice(actions)\n",
    "        actions[choice]()\n",
    "    \n",
    "    def deepen_morph(self):\n",
    "        deepen_conv_block = self.int_to_node[random.choice(self.conv_blocks)]\n",
    "        kernel_size = random.choice([3, 5])\n",
    "        in_channels, in_h, in_w = deepen_conv_block.output_shape\n",
    "        out_channels = in_channels\n",
    "        identity_conv_block = convolution_block(in_h, in_w, in_channels, out_channels, kernel_size, (kernel_size-1)/2)\n",
    "        weights = identity_conv_block.conv_layer.weight.data\n",
    "        \n",
    "        # creating identity weights\n",
    "        for channel in range(out_channels):\n",
    "            for i in range(in_channels):\n",
    "                for j in range(kernel_size):\n",
    "                    for k in range(kernel_size):\n",
    "                        weights[channel][i][j][k] = int((channel == i) and (j == k) and j == (kernel_size)/2 )\n",
    "#         print 'weights of identity conv block', weights\n",
    "        \n",
    "        ## make connections \n",
    "        identity_conv_block.describe_adj_list([deepen_conv_block], deepen_conv_block.out_adj)\n",
    "        deepen_conv_block.describe_adj_list(deepen_conv_block.in_adj, [identity_conv_block])\n",
    "\n",
    "        #### later look at creating a function for singular change to in_adj or out_adj of nodes\n",
    "        for out_node in identity_conv_block.out_adj:\n",
    "            out_node_in_adj = [identity_conv_block if (x == deepen_conv_block) else x for x in out_node.in_adj ]\n",
    "            out_node.describe_adj_list(out_node_in_adj, out_node.out_adj)\n",
    "        \n",
    "        self.add_nodes_to_network([deepen_conv_block, identity_conv_block] + identity_conv_block.out_adj)\n",
    "    \n",
    "    \n",
    "    def widen_morph(self):\n",
    "        candidate_conv_blocks = []\n",
    "        for conv_block in self.conv_blocks:\n",
    "            isCandidate = bool(len(self.adj_list[conv_block][1]))\n",
    "            for child in self.adj_list[conv_block][1]:\n",
    "                isCandidate = isCandidate and isinstance(self.int_to_node[child], convolution_block)\n",
    "            if isCandidate:\n",
    "                candidate_conv_blocks.append(conv_block)\n",
    "        if len(candidate_conv_blocks) == 0:\n",
    "            return False\n",
    "\n",
    "        parent_block_no = random.choice(candidate_conv_blocks)\n",
    "        parent_block = self.int_to_node[parent_block_no]\n",
    "        widening_factor = random.choice([2, 4])\n",
    "        in_channels, in_h, in_w = parent_block.input_shape\n",
    "        out_channels = parent_block.out_channels\n",
    "        kernel_size = parent_block.kernel_size\n",
    "        padding = parent_block.padding\n",
    "        stride = parent_block.stride\n",
    "        widened_parent_block = convolution_block(in_h, in_w, in_channels, out_channels*widening_factor, kernel_size, padding, stride)\n",
    "        original_parent_weight = parent_block.conv_layer.weight.data\n",
    "        widened_parent_weight = widened_parent_block.conv_layer.weight.data\n",
    "        widened_parent_weight[:out_channels] = original_parent_weight\n",
    "        widened_parent_weight[out_channels:] = torch.zeros((out_channels*(widening_factor-1), in_channels, kernel_size, kernel_size))\n",
    "        self.int_to_node[parent_block_no]  = widened_parent_block\n",
    "        del self.node_to_int[parent_block]\n",
    "        self.node_to_int[widened_parent_block] = parent_block_no\n",
    "        parent_out_adj = []\n",
    "        for child in parent_block.out_adj:\n",
    "            child_no = self.node_to_int[child]\n",
    "            in_channels, in_h, in_w = child.input_shape\n",
    "            out_channels = child.out_channels\n",
    "            kernel_size = child.kernel_size \n",
    "            padding = child.padding\n",
    "            stride = child.stride\n",
    "            child_widened = convolution_block(in_h, in_w, in_channels*widening_factor, out_channels, kernel_size, padding, stride)\n",
    "            child_widened.conv_layer.weight.data[:, :in_channels, :, :] = child.conv_layer.weight.data\n",
    "            child_widened.describe_adj_list([widened_parent_block if x == parent_block else x for x in child.in_adj], child.out_adj)\n",
    "            self.int_to_node[child_no] = child_widened\n",
    "            del self.node_to_int[child]\n",
    "            self.node_to_int[child_widened] = child_no\n",
    "            parent_out_adj.append(child_widened)\n",
    "        widened_parent_block.describe_adj_list(parent_block.in_adj, parent_out_adj)\n",
    "    \n",
    "    def dfs(self, curr_node, visited, weight):\n",
    "        visited[curr_node] = weight\n",
    "        for child in self.adj_list[curr_node][1]:\n",
    "            if child not in visited:\n",
    "                kernel = 0\n",
    "                padding = 0\n",
    "                constant = 0\n",
    "                child_node = self.int_to_node[child]\n",
    "                ## make adjustments for concatenation\n",
    "                if isinstance(child_node, convolution_block) or isinstance(child_node, max_pool_node):\n",
    "                    kernel = child_node.kernel_size\n",
    "                    padding = child_node.padding\n",
    "                    constant = 1\n",
    "                self.dfs(child, visited, [weight[0]+kernel, weight[1]+padding, weight[2]+constant])\n",
    "        \n",
    "        \n",
    "    def get_descendant_vectors(self):\n",
    "        descs = {}\n",
    "        for curr_node in self.nodes:\n",
    "            visited = {}\n",
    "            self.dfs(curr_node, visited, [0, 0, 0])\n",
    "            del visited[curr_node] # remove root \n",
    "            descs[curr_node] = visited\n",
    "        return descs\n",
    "        \n",
    "    def skip_morph(self):\n",
    "        descs = self.get_descendant_vectors()\n",
    "        candidates = [(ans, des) for ans in descs for des in descs[ans] ]\n",
    "        no1, no2 = random.choice(candidates)\n",
    "        weight = descs[no1][no2]\n",
    "        #join outputs of node1 and node2 using a merge block\n",
    "        node_a = self.int_to_node[no1]\n",
    "        node_b = self.int_to_node[no2]\n",
    "        out_ch_1, out_h_1, out_w_1 = node_a.output_shape\n",
    "        out_ch_2, out_h_2, out_w_2 = node_b.output_shape\n",
    "        print 'selected_nodes are ', no1, \"  \",no2\n",
    "        print 'weight is   ', weight\n",
    "        print(out_h_1, out_h_2, weight[0] - 2*weight[1] - weight[2])\n",
    "        assert(out_h_1 - out_h_2 == out_w_1 - out_w_2)\n",
    "        assert(out_h_1 - out_h_2 == weight[0] - 2*weight[1] - weight[2])\n",
    "        if weight[2] & 1 == 0:\n",
    "            weight[2] += 1\n",
    "            weight[0] += 1\n",
    "        weight[1] += (weight[2])/2\n",
    "        weight[2] -= 2*(weight[2]/2)\n",
    "        kernel_size = weight[0]\n",
    "        padding = weight[1]\n",
    "        stride = 1\n",
    "        new_conv = convolution_block(out_h_1, out_w_1, out_ch_1, out_ch_2, kernel_size, padding, stride)\n",
    "        new_add = add_node([new_conv, node_b], node_b.out_adj)\n",
    "        new_conv.describe_adj_list([node_a], [new_add])\n",
    "        new_conv.conv_layer.weight.data = torch.zeros(new_conv.conv_layer.weight.data.shape)\n",
    "        node_a.describe_adj_list(node_a.in_adj, node_a.out_adj+[new_conv])\n",
    "        for child_node in node_b.out_adj:\n",
    "            child_node.describe_adj_list([new_add if x==node_b else x for x in child_node.in_adj], child_node.out_adj)\n",
    "        node_b.describe_adj_list(node_b.in_adj, [new_add])\n",
    "        self.add_nodes_to_network([node_a, node_b, new_conv, new_add] + new_add.out_adj)\n",
    "        \n",
    "        \n",
    "        ###\n",
    "    \n",
    "    def visualize(self):\n",
    "        graph = Digraph('arch', 'arch.gv')\n",
    "        for no, curr_node in self.int_to_node.items():\n",
    "#             graph.node(str(no), str(type(curr_node)).split('__main__.')[1])\n",
    "            graph.node(str(no), str(self.node_to_int[curr_node]) + \" :: \" + repr(curr_node)[:200])\n",
    "        for no, li in self.adj_list.items():\n",
    "            for ch in li[1]:\n",
    "                graph.edge(str(no), str(ch))\n",
    "        graph.view()\n",
    "    \n",
    "    def describe(self):\n",
    "        print 'Nodes: ', self.nodes\n",
    "        print 'Conv_blocks', self.conv_blocks\n",
    "        print 'Max_pool_blocks', self.max_pool_blocks\n",
    "        print 'Adj_list', self.adj_list\n",
    "        print 'Adj_mat', self.adj_mat\n",
    "        print 'int_to_node', self.int_to_node\n",
    "        print 'node_to_int', self.node_to_int\n",
    "        print 'Toposort', self.topsort\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = node((5, 5, 5), (5, 5, 5))\n",
    "n1 = convolution_block(5, 5, 5, 4, 3)\n",
    "n2 = convolution_block(3, 3, 4, 3, 2)\n",
    "dummy.describe_adj_list([], [n1])\n",
    "n1.describe_adj_list([dummy], [n2])\n",
    "n2.describe_adj_list([n1], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network({0:[[], [1]], 1:[[0], [2]], 2: [[1], []]}, {0: dummy, 1:n1, 2:n2})\n",
    "#### remove morph function from Network class to shift to hill climbing, also kernel_size and widening factor \n",
    "#### for deepen and widen should be parameters\n",
    "### check more conformity betweeen input adj_list and input 'int_to_node'\n",
    "### check compatibility of initial arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  net.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 5)  ->  0 -> (5, 5, 5)\n",
      "(5, 5, 5)  ->  1 -> (4, 3, 3)\n",
      "(4, 3, 3)  ->  2 -> (3, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "net.visualize()\n",
    "for nan in net.nodes:\n",
    "    print net.int_to_node[nan].input_shape, ' -> ', nan, '->', net.int_to_node[nan].output_shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected_nodes are  0    4\n",
      "weight is    [5, 0, 2]\n",
      "(5, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "net.skip_morph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 5)  ->  0 -> (5, 5, 5)\n",
      "(5, 5, 5)  ->  1 -> (4, 3, 3)\n",
      "(4, 3, 3)  ->  2 -> (3, 2, 2)\n",
      "(4, 3, 3)  ->  3 -> (3, 2, 2)\n",
      "(3, 2, 2)  ->  4 -> (3, 2, 2)\n",
      "(4, 3, 3)  ->  5 -> (3, 2, 2)\n",
      "(3, 2, 2)  ->  6 -> (3, 2, 2)\n",
      "(5, 5, 5)  ->  7 -> (3, 2, 2)\n",
      "(3, 2, 2)  ->  8 -> (3, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "net.visualize()\n",
    "for nan in net.nodes:\n",
    "    print net.int_to_node[nan].input_shape, ' -> ', nan, '->', net.int_to_node[nan].output_shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.skip_morph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d =((1, 2), (3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = {'a': {'b': (1, 0, 0), 'c': (4, 5, 2)}, 'd': {'k':10}}\n",
    "[(ans, des) for ans in descs for des in descs[ans] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Error('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
